{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IATS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIDpe6EpjuUP"
      },
      "source": [
        "# IATS - Image Analysis Training School at the University of Nottingham\n",
        "## Vincenzo Della Mea, MITEL, University of Udine\n",
        "\n",
        "This [Jupyter](https://jupyter.org) notebook is aimed at introducing IATS attendants to the application of CNNs to histologic images, with an easy learning path based on [Fastai](https://www.fast.ai). It does not aim at people already expert in Python and deep learning. I suggest to take the Fastai course for Vision if you want to learn more on both the topic and on the framework.\n",
        "\n",
        "It is in no way exhaustive, and also the image data set provided cannot be considered more than an example of what can be done. \n",
        "The image set comes from a larger digital slide repository developed during the EU MSCA [AIDPATH](http://aidpath.eu) project. However, for this exercise only some image has been used.\n",
        "\n",
        "Before running code, please set the runtime type to use a GPU (Menu *Runtime: Runtime type: Hardware Accelerator: GPU*). In the same dialog, runtime type should be set as **Python 3**.\n",
        "In this specific exercise, using CPU will still result in acceptable training times, however when the training set is larger, it quickly becomes too much. If it happens that you select after having started running the code, you have to start again.\n",
        "\n",
        "---\n",
        "\n",
        "The next cells include either instructions and explanations or Python code, plus sometimes shell commands prefixed by \"!\". You may run them one by one, or all together from the \"*Runtime*\" Menu. After running a cell, the output becomes visible just behind, and is also saved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfTYUHnxXjn"
      },
      "source": [
        "The next cell is used to setup the Fastai environment, and to include useful libraries. Click on the \"[ ]\" icon on the left side to run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnqodo9XkfJF"
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqu5xqLWycRr"
      },
      "source": [
        "Now let's import the image set we will use for the exercise. We will get it from MITEL web site.\n",
        "**Do not redistribute the image set: it is not validated and not meant for general public.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY-sx9zOyh32"
      },
      "source": [
        "!wget  --no-check-certificate https://mitel.dimi.uniud.it/IATS/IATS.zip\n",
        "with ZipFile('IATS.zip', 'r') as zf:\n",
        "    zf.extractall('data/')\n",
        "!ls data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ_qou8K0K6u"
      },
      "source": [
        "Now set some parameters used in the process. \n",
        "Regarding the model, you may find a list [here](https://docs.fast.ai/vision.models.html).\n",
        "With the parameters chosen, we will do transfer learning on a a model pretrained on the [Imagenet](http://www.image-net.org) image set. This will save us time (less epochs needed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdt_m7ld0SqV"
      },
      "source": [
        "path='data/IATS'\n",
        "batch_size=32 #this can be changed because it effects results, however if too large, GPU memory will not suffice\n",
        "resize=256 #current CNN model use very small images (e.g., 224x224); you can let this be as large as our images (512) but not too much\n",
        "model = models.resnet34 #you may try with other pretrained models, e.g.,  resnet152\n",
        "epochs=2\n",
        "outfile = 'predictions.csv'\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeuQCogL00RP"
      },
      "source": [
        "In the next cell we prepare the learner object (*classifier*), starting from the transformed and normalised image set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePEVMT8G1YkJ"
      },
      "source": [
        "tfms = get_transforms(max_zoom=1.1) #to augment the data set,  a number of transformations is usually done, e.g., flipping, rotating, slight zooming, etc\n",
        "images = ImageDataBunch.from_folder(path,ds_tfms=tfms, size=resize, bs=batch_size,test='test')\n",
        "images.normalize(imagenet_stats)\n",
        "classifier = cnn_learner(images, model, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ZAZMs620zF"
      },
      "source": [
        "Before starting the process, let's look at our images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kedoPEPPLGW"
      },
      "source": [
        "images.show_batch(rows=4, figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkDCGnGt2UQK"
      },
      "source": [
        "## Training\n",
        "Finally, we  can start **training**. Done this way, only the last layer of the network is trained. It could be sufficient or not, depending on the image set. You will see the output epoch by epoch, including accuracy on the validation set (but be careful, not always accuracy is sufficient to evaluate performance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHDnq1rh3JrF"
      },
      "source": [
        "classifier.fit_one_cycle(epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWnrUCFh3w7l"
      },
      "source": [
        "In a complete process, you may want to train also the first layers of the network, typically after having trained the last as above, and for less epochs. To do so, you have to \"unfreeze\" the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kczbccka4BQm"
      },
      "source": [
        "classifier.unfreeze()\n",
        "classifier.fit_one_cycle(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHPDD5I_4QHp"
      },
      "source": [
        "Before classifying our test set, let's look at results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dpUTLdY4Oip"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(classifier)\n",
        "#losses,idxs = interp.top_losses()\n",
        "#len(images.valid_ds)==len(losses)==len(idxs)\n",
        "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
        "interp.most_confused(min_val=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pj9zG-mO2iP"
      },
      "source": [
        "interp.plot_top_losses(9, figsize=(12,12), heatmap=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVNCOYD5NxMG"
      },
      "source": [
        "classifier.show_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqXNLOxf5QCH"
      },
      "source": [
        "## Predictions\n",
        "We can finally predict the classes for the test set. There are other ways of doing this. \n",
        "The output is a CSV file with the proposed class (all those >0.6 probability), and also the probability of each class. \n",
        "If you have more than two classes, you might have more than one proposed class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO9OFZKH5DPN",
        "outputId": "013a3a06-f6f3-4871-c987-3fed162d0140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "preds, y = classifier.get_preds(ds_type=DatasetType.Test)\n",
        "thresh = 0.6\n",
        "labelled_preds = [' '.join([classifier.data.classes[i] for i,p in enumerate(pred) if p > thresh]) for pred in preds]\n",
        "fnames = [f.name[:-2] for f in classifier.data.test_ds.items]\n",
        "df = pd.DataFrame({'image_name':fnames, 'class':labelled_preds, 'NonCancer':preds.numpy()[:, 0], 'Cancer':preds.numpy()[:, 1]}, \n",
        "                  columns=['image_name', 'class','NonCancer','Cancer'])\n",
        "df.to_csv(outfile, index=False)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEWlQhusvO3f"
      },
      "source": [
        "The next cell downloads the CSV file on your computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rug8uoH_Jj3"
      },
      "source": [
        "files.download(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FvX5qJPnVcX"
      },
      "source": [
        "## Some extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ4e81hKA5zp"
      },
      "source": [
        "The next cell let you copy images from your Google Drive, assuming you have a \"mydata\" folder with a zip file inside that contains the folder structure for Fastai.\n",
        "You may put this instead of the second code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMfKzgKEAzCF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls gdrive\n",
        "# In principle, you may also directly work with the folder structure directly stored on Google Drive,\n",
        "# but file access is much slower, and you will spend more time in training. Better to move on the Colab disk. \n",
        "with ZipFile('/content/gdrive/My Drive/mydata/IATS.zip', 'r') as zf:\n",
        "    zf.extractall('data/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKF5lFIs7VGq"
      },
      "source": [
        "You may save the trained model for further use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adcrI9n7VWb"
      },
      "source": [
        "classifier.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shfM021pVg_b"
      },
      "source": [
        "Fastai has a method to random split a training set to obtain the validation set. \n",
        "However, the next cell shows how to do it from the shell: put all training images in the train folder, then launch the commands below. Substitute 200 with the number of images you want in each class in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df_AbzHGU5x1"
      },
      "source": [
        "!shuf -n 200 -e data/train/0-NonCancer/* | xargs -I{} mv {} data/valid/0-NonCancer/\n",
        "!shuf -n 200 -e data/train/1-Cancer/* | xargs -I{} mv {} data/valid/1-Cancer/\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
